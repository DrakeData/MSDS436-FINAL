{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook gathers the necissary data from 3 different data sources:\n",
    " - 2022Q3 Divvy bike/trip data found on [Divvy's Data Portal](https://divvy-tripdata.s3.amazonaws.com/index.html)\n",
    " - Estimated travel time using  [Open Source Routing Machine (OSRM) API](http://project-osrm.org/docs/v5.10.0/api/#general-options)\n",
    " - Historic weather data from [OpenWeather API](https://openweathermap.org/api/one-call-3#data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Setup Libraries and File Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import datetime\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from scrapy.selector import Selector\n",
    "import numpy as np\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create file location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Nicholas\\\\Desktop\\\\Masters - Classes\\\\MSDS436\\\\Final\\\\MSDS436-FINAL\\\\DATA'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT = os.getcwd()\n",
    "SAVE_FILES = os.path.join(ROOT, \"DATA\")\n",
    "SAVE_FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Pull the September Divvy Bike Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(f\"https://divvy-tripdata.s3.amazonaws.com/202209-divvy-tripdata.zip\")\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall(SAVE_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sept_df = pd.read_csv('C:\\\\Users\\\\Nicholas\\\\Desktop\\\\Masters - Classes\\\\MSDS436\\\\Final\\\\MSDS436-FINAL\\\\DATA\\\\202209-divvy-publictripdata.csv')\n",
    "sept_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clean data\n",
    "- Order start_at in decending order\n",
    "- Drop all rows that do not have a start and end station\n",
    "- Pull between 1,000-2,000 data points per day\n",
    "- Pull weather data for 24h per day (720 rows total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order start_at in decending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sept_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sept_df['started_at'] = pd.to_datetime(sept_df['started_at'])\n",
    "sept_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sept_df = sept_df.sort_values(by='started_at')\n",
    "\n",
    "display(len(sept_df))\n",
    "sept_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all rows that do not have a start and end station name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sept_df = sept_df[sept_df['start_station_name'].notnull()]\n",
    "sept_df = sept_df[sept_df['end_station_name'].notnull()]\n",
    "\n",
    "display(len(sept_df))\n",
    "sept_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab up to 2,000 rows per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get just date column\n",
    "sept_df['started_at_clean'] = sept_df['started_at'].dt.date.astype(str)\n",
    "sept_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unique date list\n",
    "date_ls = sept_df['started_at_clean'].unique().tolist()\n",
    "date_ls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for date in date_ls:\n",
    "    if cnt == 0:\n",
    "        main_df = sept_df[sept_df['started_at_clean'] == date].sample(n=2000, random_state=0)\n",
    "        cnt =+ 1\n",
    "    else:\n",
    "        filter_df = sept_df[sept_df['started_at_clean'] == date].sample(n=2000, random_state=0)\n",
    "        main_df = pd.concat([main_df, filter_df], ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(len(main_df))\n",
    "\n",
    "main_df.index.name = 'row'\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check data\n",
    "# main_df.to_csv(\"data_check.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Get estimated travel time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new method per https://github.com/Project-OSRM/osrm-backend/issues/6258\n",
    "def get_distance_bike(point1: dict, point2: dict) -> tuple:\n",
    "    \"\"\"Gets distance between two points en route using http://project-osrm.org/docs/v5.10.0/api/#nearest-service\"\"\"\n",
    "    \n",
    "    url = f\"\"\"https://routing.openstreetmap.de/routed-bike/route/v1/biking/{point1[\"start_lng\"]},{point1[\"start_lat\"]};{point2[\"end_lng\"]},{point2[\"end_lat\"]}?overview=false&alternatives=false\"\"\"\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    # get the distance from the returned values\n",
    "    route = json.loads(r.content)[\"routes\"][0]\n",
    "    return (route[\"distance\"], route[\"duration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distances and durations\n",
    "dist_array_bike = []\n",
    "for i , r in tqdm(main_df.iterrows()):\n",
    "    try:\n",
    "        point1 = {\"start_lat\": r[\"start_lat\"], \"start_lng\": r[\"start_lng\"]}\n",
    "        point2 = {\"end_lat\": r[\"end_lat\"], \"end_lng\": r[\"end_lng\"]}\n",
    "        dist, duration = get_distance_bike(point1, point2)\n",
    "        #dist = geodesic((i_lat, i_lon), (o[\"CapitalLatitude\"], o[\"CapitalLongitude\"])).km\n",
    "        dist_array_bike.append((i, duration, dist))\n",
    "    except KeyError:\n",
    "        dist_array_bike.append((i, 0, 0))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_bike_df = pd.DataFrame(dist_array_bike,columns=[\"row\",\"duration (s)\",\"distance (m)\"])\n",
    "\n",
    "display(len(distances_bike_df))\n",
    "distances_bike_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matches key value for 'row' or any other unique identifier we want to assign later on\n",
    "sep_dis_df = pd.merge(main_df, distances_bike_df, on='row', how='right').drop('row', axis=1)\n",
    "sep_dis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data frame\n",
    "sep_dis_df.to_csv(\"DATA/202209_divvy_distance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Collect historic weather data\n",
    "- Chicago lat: 41.87\n",
    "- Chicago long: 87.62\n",
    "- Pull hourly data for all 30 days (720 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load save file\n",
    "sep_dis_df = pd.read_csv(\"DATA/202209_divvy_distance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>started_at_clean</th>\n",
       "      <th>duration (s)</th>\n",
       "      <th>distance (m)</th>\n",
       "      <th>started_at_unix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2FD3F90EDCE2ACD9</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-09-01 19:39:15</td>\n",
       "      <td>2022-09-01 19:46:45</td>\n",
       "      <td>Southport Ave &amp; Roscoe St</td>\n",
       "      <td>13071</td>\n",
       "      <td>Broadway &amp; Cornelia Ave</td>\n",
       "      <td>13278</td>\n",
       "      <td>41.943739</td>\n",
       "      <td>-87.664020</td>\n",
       "      <td>41.945529</td>\n",
       "      <td>-87.646439</td>\n",
       "      <td>member</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>481.9</td>\n",
       "      <td>1669.2</td>\n",
       "      <td>1662058800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EE62794A94F80A83</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-09-01 06:53:41</td>\n",
       "      <td>2022-09-01 07:02:54</td>\n",
       "      <td>LaSalle St &amp; Washington St</td>\n",
       "      <td>13006</td>\n",
       "      <td>Wells St &amp; Polk St</td>\n",
       "      <td>SL-011</td>\n",
       "      <td>41.882664</td>\n",
       "      <td>-87.632530</td>\n",
       "      <td>41.872732</td>\n",
       "      <td>-87.633516</td>\n",
       "      <td>casual</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>395.0</td>\n",
       "      <td>1358.8</td>\n",
       "      <td>1662012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56FD4B364747F270</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-09-01 11:25:21</td>\n",
       "      <td>2022-09-01 11:28:33</td>\n",
       "      <td>N Sheffield Ave &amp; W Wellington Ave</td>\n",
       "      <td>20256.0</td>\n",
       "      <td>Southport Ave &amp; Wellington Ave</td>\n",
       "      <td>TA1307000006</td>\n",
       "      <td>41.940000</td>\n",
       "      <td>-87.650000</td>\n",
       "      <td>41.935733</td>\n",
       "      <td>-87.663576</td>\n",
       "      <td>casual</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>411.5</td>\n",
       "      <td>1595.7</td>\n",
       "      <td>1662030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BD4D6AC842CDF729</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-09-01 07:46:03</td>\n",
       "      <td>2022-09-01 08:05:36</td>\n",
       "      <td>Racine Ave &amp; Wrightwood Ave</td>\n",
       "      <td>TA1309000059</td>\n",
       "      <td>DuSable Lake Shore Dr &amp; North Blvd</td>\n",
       "      <td>LF-005</td>\n",
       "      <td>41.928887</td>\n",
       "      <td>-87.658971</td>\n",
       "      <td>41.911722</td>\n",
       "      <td>-87.626804</td>\n",
       "      <td>casual</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>948.8</td>\n",
       "      <td>3643.8</td>\n",
       "      <td>1662015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2E0E8C378865C01A</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-09-01 09:55:31</td>\n",
       "      <td>2022-09-01 10:12:27</td>\n",
       "      <td>Wabash Ave &amp; Adams St</td>\n",
       "      <td>KA1503000015</td>\n",
       "      <td>Wood St &amp; Taylor St (Temp)</td>\n",
       "      <td>13285</td>\n",
       "      <td>41.879373</td>\n",
       "      <td>-87.625492</td>\n",
       "      <td>41.869265</td>\n",
       "      <td>-87.673731</td>\n",
       "      <td>member</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>1275.1</td>\n",
       "      <td>5104.7</td>\n",
       "      <td>1662022800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id  rideable_type           started_at             ended_at  \\\n",
       "0  2FD3F90EDCE2ACD9   classic_bike  2022-09-01 19:39:15  2022-09-01 19:46:45   \n",
       "1  EE62794A94F80A83   classic_bike  2022-09-01 06:53:41  2022-09-01 07:02:54   \n",
       "2  56FD4B364747F270  electric_bike  2022-09-01 11:25:21  2022-09-01 11:28:33   \n",
       "3  BD4D6AC842CDF729   classic_bike  2022-09-01 07:46:03  2022-09-01 08:05:36   \n",
       "4  2E0E8C378865C01A  electric_bike  2022-09-01 09:55:31  2022-09-01 10:12:27   \n",
       "\n",
       "                   start_station_name start_station_id  \\\n",
       "0           Southport Ave & Roscoe St            13071   \n",
       "1          LaSalle St & Washington St            13006   \n",
       "2  N Sheffield Ave & W Wellington Ave          20256.0   \n",
       "3         Racine Ave & Wrightwood Ave     TA1309000059   \n",
       "4               Wabash Ave & Adams St     KA1503000015   \n",
       "\n",
       "                     end_station_name end_station_id  start_lat  start_lng  \\\n",
       "0             Broadway & Cornelia Ave          13278  41.943739 -87.664020   \n",
       "1                  Wells St & Polk St         SL-011  41.882664 -87.632530   \n",
       "2      Southport Ave & Wellington Ave   TA1307000006  41.940000 -87.650000   \n",
       "3  DuSable Lake Shore Dr & North Blvd         LF-005  41.928887 -87.658971   \n",
       "4          Wood St & Taylor St (Temp)          13285  41.879373 -87.625492   \n",
       "\n",
       "     end_lat    end_lng member_casual started_at_clean  duration (s)  \\\n",
       "0  41.945529 -87.646439        member       2022-09-01         481.9   \n",
       "1  41.872732 -87.633516        casual       2022-09-01         395.0   \n",
       "2  41.935733 -87.663576        casual       2022-09-01         411.5   \n",
       "3  41.911722 -87.626804        casual       2022-09-01         948.8   \n",
       "4  41.869265 -87.673731        member       2022-09-01        1275.1   \n",
       "\n",
       "   distance (m)  started_at_unix  \n",
       "0        1669.2       1662058800  \n",
       "1        1358.8       1662012000  \n",
       "2        1595.7       1662030000  \n",
       "3        3643.8       1662015600  \n",
       "4        5104.7       1662022800  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep_dis_df['started_at_unix'] = pd.to_datetime(sep_dis_df['started_at'])\n",
    "sep_dis_df['started_at_unix'] = pd.to_datetime(sep_dis_df['started_at_unix'].dt.strftime('%Y-%m-%d %H'))\n",
    "sep_dis_df['started_at_unix'] = pd.to_numeric(sep_dis_df['started_at_unix'])\n",
    "sep_dis_df['started_at_unix'] = sep_dis_df['started_at_unix'] // 10 ** 9\n",
    "\n",
    "\n",
    "sep_dis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1662058800, 1662012000, 1662030000, 1662015600, 1662022800]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get unique list of unix times\n",
    "unix_dt_ls = sep_dis_df['started_at_unix'].unique().tolist()\n",
    "display(unix_dt_ls[:5])\n",
    "display(len(unix_dt_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weathermap(latnum, lngnum, dtnum):\n",
    "    '''\n",
    "    Pulls weather data using lat, long, and unix_dt\n",
    "    '''\n",
    "    api_url = f\"http://api.openweathermap.org/data/3.0/onecall/timemachine?lat={latnum}&lon={lngnum}&dt={dtnum}&units=imperial&appid={config.api_key}\"\n",
    "    response = requests.get(api_url)\n",
    "    resp = response.json()\n",
    "    \n",
    "    temp = resp['data'][0]['temp']\n",
    "    hum = resp['data'][0]['humidity']\n",
    "    windsp = resp['data'][0]['wind_speed']\n",
    "    weather = resp['data'][0]['weather'][0]['main']\n",
    "    try:\n",
    "        rain = resp['data'][0]['rain']['1h']\n",
    "    except KeyError as ke:\n",
    "        rain = 0    \n",
    "    try:\n",
    "        snow = resp['data'][0]['snow']['1h']\n",
    "    except KeyError as ke:\n",
    "        snow = 0\n",
    "    \n",
    "    return temp, hum, windsp, weather, rain, snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 696/696 [08:45<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "temp_ls = []\n",
    "hum_ls = []\n",
    "windsp_ls = []\n",
    "weather_ls = []\n",
    "rain_ls = []\n",
    "snow_ls = []\n",
    "\n",
    "\n",
    "for unix in tqdm(unix_dt_ls):\n",
    "    try:\n",
    "        latnum = 41.87\n",
    "        lngnum = -87.62\n",
    "        dtnum = unix\n",
    "        data = weathermap(latnum, lngnum, dtnum)\n",
    "        temp_ls.append(data[0])\n",
    "        hum_ls.append(data[1])\n",
    "        windsp_ls.append(data[2])\n",
    "        weather_ls.append(data[3])\n",
    "        rain_ls.append(data[4])\n",
    "        snow_ls.append(data[5])\n",
    "    except NameError:\n",
    "        temp_ls.append('Nan')\n",
    "        hum_ls.append('Nan')\n",
    "        windsp_ls.append('Nan')\n",
    "        weather_ls.append('Nan')\n",
    "        rain_ls.append('Nan')\n",
    "        snow_ls.append('Nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lat': 41.87,\n",
       " 'lon': -87.62,\n",
       " 'timezone': 'America/Chicago',\n",
       " 'timezone_offset': -18000,\n",
       " 'data': [{'dt': 1664568000,\n",
       "   'sunrise': 1664538373,\n",
       "   'sunset': 1664580873,\n",
       "   'temp': 61.39,\n",
       "   'feels_like': 59.86,\n",
       "   'pressure': 1024,\n",
       "   'humidity': 56,\n",
       "   'dew_point': 45.57,\n",
       "   'clouds': 0,\n",
       "   'visibility': 10000,\n",
       "   'wind_speed': 10.36,\n",
       "   'wind_deg': 90,\n",
       "   'wind_gust': 18.41,\n",
       "   'weather': [{'id': 800,\n",
       "     'main': 'Clear',\n",
       "     'description': 'clear sky',\n",
       "     'icon': '01d'}]}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # API Check\n",
    "\n",
    "# latnum = 41.87\n",
    "# lngnum = -87.62\n",
    "\n",
    "# api_url = f\"http://api.openweathermap.org/data/3.0/onecall/timemachine?lat={latnum}&lon={lngnum}&dt=1664568000&units=imperial&appid={config.api_key}\"\n",
    "# response = requests.get(api_url)\n",
    "# resp = response.json()\n",
    "\n",
    "# resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>started_at_unix</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windsp</th>\n",
       "      <th>weather</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1662008400</td>\n",
       "      <td>75.45</td>\n",
       "      <td>69</td>\n",
       "      <td>1.99</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1662012000</td>\n",
       "      <td>73.87</td>\n",
       "      <td>71</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1662015600</td>\n",
       "      <td>73.27</td>\n",
       "      <td>72</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1662019200</td>\n",
       "      <td>72.34</td>\n",
       "      <td>74</td>\n",
       "      <td>1.99</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1662022800</td>\n",
       "      <td>71.74</td>\n",
       "      <td>75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   started_at_unix   temp  hum  windsp weather  rain  snow\n",
       "0       1662008400  75.45   69    1.99   Clear   0.0     0\n",
       "1       1662012000  73.87   71    1.01   Clear   0.0     0\n",
       "2       1662015600  73.27   72    1.01   Clear   0.0     0\n",
       "3       1662019200  72.34   74    1.99   Clear   0.0     0\n",
       "4       1662022800  71.74   75    1.99   Clear   0.0     0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = pd.DataFrame(list(zip(unix_dt_ls, temp_ls, hum_ls, windsp_ls, \n",
    "                                weather_ls, rain_ls, snow_ls)),\n",
    "               columns =['started_at_unix', 'temp', 'hum', 'windsp', \n",
    "                         'weather', 'rain', 'snow'])\n",
    "\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>started_at_unix</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windsp</th>\n",
       "      <th>weather</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1662012000</td>\n",
       "      <td>73.87</td>\n",
       "      <td>71</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   started_at_unix   temp  hum  windsp weather  rain  snow\n",
       "1       1662012000  73.87   71    1.01   Clear   0.0     0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data check\n",
    "weather_df[weather_df['started_at_unix']== 1662012000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>...</th>\n",
       "      <th>started_at_clean</th>\n",
       "      <th>duration (s)</th>\n",
       "      <th>distance (m)</th>\n",
       "      <th>started_at_unix</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windsp</th>\n",
       "      <th>weather</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2FD3F90EDCE2ACD9</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-09-01 19:39:15</td>\n",
       "      <td>2022-09-01 19:46:45</td>\n",
       "      <td>Southport Ave &amp; Roscoe St</td>\n",
       "      <td>13071</td>\n",
       "      <td>Broadway &amp; Cornelia Ave</td>\n",
       "      <td>13278</td>\n",
       "      <td>41.943739</td>\n",
       "      <td>-87.664020</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>481.9</td>\n",
       "      <td>1669.2</td>\n",
       "      <td>1662058800</td>\n",
       "      <td>90.05</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EE62794A94F80A83</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-09-01 06:53:41</td>\n",
       "      <td>2022-09-01 07:02:54</td>\n",
       "      <td>LaSalle St &amp; Washington St</td>\n",
       "      <td>13006</td>\n",
       "      <td>Wells St &amp; Polk St</td>\n",
       "      <td>SL-011</td>\n",
       "      <td>41.882664</td>\n",
       "      <td>-87.632530</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>395.0</td>\n",
       "      <td>1358.8</td>\n",
       "      <td>1662012000</td>\n",
       "      <td>73.87</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56FD4B364747F270</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-09-01 11:25:21</td>\n",
       "      <td>2022-09-01 11:28:33</td>\n",
       "      <td>N Sheffield Ave &amp; W Wellington Ave</td>\n",
       "      <td>20256.0</td>\n",
       "      <td>Southport Ave &amp; Wellington Ave</td>\n",
       "      <td>TA1307000006</td>\n",
       "      <td>41.940000</td>\n",
       "      <td>-87.650000</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>411.5</td>\n",
       "      <td>1595.7</td>\n",
       "      <td>1662030000</td>\n",
       "      <td>73.06</td>\n",
       "      <td>75.0</td>\n",
       "      <td>8.10</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BD4D6AC842CDF729</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-09-01 07:46:03</td>\n",
       "      <td>2022-09-01 08:05:36</td>\n",
       "      <td>Racine Ave &amp; Wrightwood Ave</td>\n",
       "      <td>TA1309000059</td>\n",
       "      <td>DuSable Lake Shore Dr &amp; North Blvd</td>\n",
       "      <td>LF-005</td>\n",
       "      <td>41.928887</td>\n",
       "      <td>-87.658971</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>948.8</td>\n",
       "      <td>3643.8</td>\n",
       "      <td>1662015600</td>\n",
       "      <td>73.27</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2E0E8C378865C01A</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-09-01 09:55:31</td>\n",
       "      <td>2022-09-01 10:12:27</td>\n",
       "      <td>Wabash Ave &amp; Adams St</td>\n",
       "      <td>KA1503000015</td>\n",
       "      <td>Wood St &amp; Taylor St (Temp)</td>\n",
       "      <td>13285</td>\n",
       "      <td>41.879373</td>\n",
       "      <td>-87.625492</td>\n",
       "      <td>...</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>1275.1</td>\n",
       "      <td>5104.7</td>\n",
       "      <td>1662022800</td>\n",
       "      <td>71.74</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>Clear</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id  rideable_type           started_at             ended_at  \\\n",
       "0  2FD3F90EDCE2ACD9   classic_bike  2022-09-01 19:39:15  2022-09-01 19:46:45   \n",
       "1  EE62794A94F80A83   classic_bike  2022-09-01 06:53:41  2022-09-01 07:02:54   \n",
       "2  56FD4B364747F270  electric_bike  2022-09-01 11:25:21  2022-09-01 11:28:33   \n",
       "3  BD4D6AC842CDF729   classic_bike  2022-09-01 07:46:03  2022-09-01 08:05:36   \n",
       "4  2E0E8C378865C01A  electric_bike  2022-09-01 09:55:31  2022-09-01 10:12:27   \n",
       "\n",
       "                   start_station_name start_station_id  \\\n",
       "0           Southport Ave & Roscoe St            13071   \n",
       "1          LaSalle St & Washington St            13006   \n",
       "2  N Sheffield Ave & W Wellington Ave          20256.0   \n",
       "3         Racine Ave & Wrightwood Ave     TA1309000059   \n",
       "4               Wabash Ave & Adams St     KA1503000015   \n",
       "\n",
       "                     end_station_name end_station_id  start_lat  start_lng  \\\n",
       "0             Broadway & Cornelia Ave          13278  41.943739 -87.664020   \n",
       "1                  Wells St & Polk St         SL-011  41.882664 -87.632530   \n",
       "2      Southport Ave & Wellington Ave   TA1307000006  41.940000 -87.650000   \n",
       "3  DuSable Lake Shore Dr & North Blvd         LF-005  41.928887 -87.658971   \n",
       "4          Wood St & Taylor St (Temp)          13285  41.879373 -87.625492   \n",
       "\n",
       "   ...  started_at_clean  duration (s) distance (m) started_at_unix   temp  \\\n",
       "0  ...        2022-09-01         481.9       1669.2      1662058800  90.05   \n",
       "1  ...        2022-09-01         395.0       1358.8      1662012000  73.87   \n",
       "2  ...        2022-09-01         411.5       1595.7      1662030000  73.06   \n",
       "3  ...        2022-09-01         948.8       3643.8      1662015600  73.27   \n",
       "4  ...        2022-09-01        1275.1       5104.7      1662022800  71.74   \n",
       "\n",
       "    hum  windsp  weather  rain  snow  \n",
       "0  39.0    4.00   Clouds   0.0   0.0  \n",
       "1  71.0    1.01    Clear   0.0   0.0  \n",
       "2  75.0    8.10    Clear   0.0   0.0  \n",
       "3  72.0    1.01    Clear   0.0   0.0  \n",
       "4  75.0    1.99    Clear   0.0   0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join data frames on started_at_unix\n",
    "sep_dis_weath_df = sep_dis_df.merge(weather_df, on='started_at_unix', how='left')\n",
    "sep_dis_weath_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export final data\n",
    "sep_dis_weath_df.to_csv(\"DATA/202209_divvy_distance_weather.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Script\n",
    "If we had more time, we would use the below code to pull a years worthof bike data and loop through the APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Pull Divvy Bike Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull keys from website using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = 'https://divvy-tripdata.s3.amazonaws.com'\n",
    "page = requests.get(main_url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_keys = soup.findAll('key')\n",
    "len(zip_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through Keys and only keep divvy-tripdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_ls = []\n",
    "\n",
    "for i in tqdm(range(len(zip_keys))):\n",
    "    key_ls.append(zip_keys[i].text)\n",
    "\n",
    "key_ls_clean = [ x for x in key_ls if \"divvy-tripdata\" in x ]\n",
    "\n",
    "key_ls_clean[27:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull and save all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for zip_f in key_ls_clean[27:30]:\n",
    "    r = requests.get(f\"https://divvy-tripdata.s3.amazonaws.com/{zip_f}\")\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    z.extractall(SAVE_FILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For our data purpose, read in the 2022Q3 files and create 1 master file\n",
    "- '202207-divvy-tripdata.csv',\n",
    "- '202208-divvy-tripdata.csv',\n",
    "- '202209-divvy-tripdata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 202207, 202208, and 202209 files and save file path in list\n",
    "file_ls = []\n",
    "\n",
    "for file in os.listdir(SAVE_FILES):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_ls.append(os.path.join(SAVE_FILES, file))\n",
    "    \n",
    "file_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through files, create pandas data frame, and save in dictonary\n",
    "df_dict = {}\n",
    "\n",
    "for i in file_ls:\n",
    "    for num in range(len(file_ls)):\n",
    "        df = pd.read_csv(i)\n",
    "        df_dict[f\"df_{num}\"] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab dictonary keys and check dataframe\n",
    "dict_keys_ls = list(df_dict.keys())\n",
    "df_dict[dict_keys_ls[2]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_df = df_dict[dict_keys_ls[2]]\n",
    "sep_df.index.name = 'row'\n",
    "len(sep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_df[:10000].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concat all 3 data frames and generate Q3_df\n",
    "# Q3_df = pd.concat([df_dict[dict_keys_ls[0]], df_dict[dict_keys_ls[1]], df_dict[dict_keys_ls[2]]], ignore_index=True, axis=0)\n",
    "# display(len(Q3_df))\n",
    "# display(Q3_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get random sample from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(n=883, random_state=0)\n",
    "display(len(df_sample))\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get estimated travel time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new method per https://github.com/Project-OSRM/osrm-backend/issues/6258\n",
    "def get_distance_bike(point1: dict, point2: dict) -> tuple:\n",
    "    \"\"\"Gets distance between two points en route using http://project-osrm.org/docs/v5.10.0/api/#nearest-service\"\"\"\n",
    "    \n",
    "    url = f\"\"\"https://routing.openstreetmap.de/routed-bike/route/v1/biking/{point1[\"start_lng\"]},{point1[\"start_lat\"]};{point2[\"end_lng\"]},{point2[\"end_lat\"]}?overview=false&alternatives=false\"\"\"\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    # get the distance from the returned values\n",
    "    route = json.loads(r.content)[\"routes\"][0]\n",
    "    return (route[\"distance\"], route[\"duration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distances and durations\n",
    "dist_array_bike = []\n",
    "for i , r in tqdm(sep_df.iterrows()):\n",
    "    try:\n",
    "        point1 = {\"start_lat\": r[\"start_lat\"], \"start_lng\": r[\"start_lng\"]}\n",
    "        point2 = {\"end_lat\": r[\"end_lat\"], \"end_lng\": r[\"end_lng\"]}\n",
    "        dist, duration = get_distance_bike(point1, point2)\n",
    "        #dist = geodesic((i_lat, i_lon), (o[\"CapitalLatitude\"], o[\"CapitalLongitude\"])).km\n",
    "        dist_array_bike.append((i, duration, dist))\n",
    "    except KeyError:\n",
    "        dist_array_bike.append((i, 0, 0))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_array_bike[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure values are different\n",
    "# print(dist_array_car) ---> [(0, 800.9, 3224.7), (1, 1289.7, 4141.1)]\n",
    "print(len(dist_array_bike))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_bike_df = pd.DataFrame(dist_array_bike,columns=[\"row\",\"duration (s)\",\"distance (m)\"])\n",
    "distances_bike_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matches key value for 'row' or any other unique identifier we want to assign later on\n",
    "sep_dis_df = pd.merge(sep_df.iloc[:290673], distances_bike_df, on='row', how='right').drop('row', axis=1)\n",
    "sep_dis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data frame\n",
    "sep_dis_df.to_csv(\"202209_divvy_distance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# export master file\n",
    "# Q3_df.to_csv(\"2022Q3_divvy-tripdata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Collect historic weather data\n",
    "**NOTE:** the config.py file contains api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data for weatehr API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round lat and long to 2 decimal places (needed for API)\n",
    "sep_dis_df['start_lat_clean'] = sep_dis_df['start_lat'].round(2)\n",
    "sep_dis_df['start_lng_clean'] = sep_dis_df['start_lng'].round(2)\n",
    "\n",
    "sep_dis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_dis_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_dis_df['unix_dt'] = pd.to_datetime(sep_dis_df['started_at'])\n",
    "sep_dis_df['unix_dt'] = pd.to_datetime(sep_dis_df['unix_dt'])\n",
    "sep_dis_df['unix_dt'] = pd.to_numeric(sep_dis_df['unix_dt'])\n",
    "sep_dis_df['unix_dt'] = sep_dis_df['unix_dt'] // 10 ** 9\n",
    "\n",
    "sep_dis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weathermap(latnum, lngnum, dtnum):\n",
    "    '''\n",
    "    Pulls weather data using lat, long, and unix_dt\n",
    "    '''\n",
    "    api_url = f\"http://api.openweathermap.org/data/3.0/onecall/timemachine?lat={latnum}&lon={lngnum}&dt={dtnum}&units=imperial&appid={config.api_key}\"\n",
    "    response = requests.get(api_url)\n",
    "    resp = response.json()\n",
    "    \n",
    "    temp = resp['data'][0]['temp']\n",
    "    hum = resp['data'][0]['humidity']\n",
    "    windsp = resp['data'][0]['wind_speed']\n",
    "    weather = resp['data'][0]['weather'][0]['main']\n",
    "    try:\n",
    "        rain = resp['data'][0]['rain']['1h']\n",
    "    except KeyError as ke:\n",
    "        rain = 0    \n",
    "    try:\n",
    "        snow = resp['data'][0]['snow']['1h']\n",
    "    except KeyError as ke:\n",
    "        snow = 0\n",
    "    \n",
    "    return temp, hum, windsp, weather, rain, snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ls = []\n",
    "hum_ls = []\n",
    "windsp_ls = []\n",
    "weather_ls = []\n",
    "rain_ls = []\n",
    "snow_ls = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(sep_dis_df))):\n",
    "    try:\n",
    "        latnum = sep_dis_df['start_lat'].iloc[i]\n",
    "        lngnum = sep_dis_df['start_lng'].iloc[i]\n",
    "        dtnum = sep_dis_df['unix_dt'].iloc[i]\n",
    "        temp_ls.append(weathermap(latnum, lngnum, dtnum)[0])\n",
    "        hum_ls.append(weathermap(latnum, lngnum, dtnum)[1])\n",
    "        windsp_ls.append(weathermap(latnum, lngnum, dtnum)[2])\n",
    "        weather_ls.append(weathermap(latnum, lngnum, dtnum)[3])\n",
    "        rain_ls.append(weathermap(latnum, lngnum, dtnum)[4])\n",
    "        snow_ls.append(weathermap(latnum, lngnum, dtnum)[5])\n",
    "    except NameError:\n",
    "        temp_ls.append('Nan')\n",
    "        hum_ls.append('Nan')\n",
    "        windsp_ls.append('Nan')\n",
    "        weather_ls.append('Nan')\n",
    "        rain_ls.append('Nan')\n",
    "        snow_ls.append('Nan')\n",
    "    \n",
    "sep_dis_df['temp'] = temp_ls\n",
    "sep_dis_df['hum'] = hum_ls\n",
    "sep_dis_df['windsp'] = windsp_ls\n",
    "sep_dis_df['weather'] = weather_ls\n",
    "sep_dis_df['rain'] = rain_ls\n",
    "sep_dis_df['snow'] = snow_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join historic weather data to sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temp'] = temp_ls\n",
    "df['hum'] = hum_ls\n",
    "df['windsp'] = windsp_ls\n",
    "df['weather'] = weather_ls\n",
    "df['rain'] = rain_ls\n",
    "df['snow'] = snow_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data in AWS S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latnum = sep_dis_df['start_lat'].iloc[0]\n",
    "latnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lngnum = sep_dis_df['start_lng'].iloc[0]\n",
    "lngnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtnum = sep_dis_df['unix_dt'].iloc[i]\n",
    "dtnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = f\"http://api.openweathermap.org/data/3.0/onecall/timemachine?lat={latnum}&lon={lngnum}&dt={dtnum}&units=imperial&appid={config.api_key}\"\n",
    "response = requests.get(api_url)\n",
    "resp = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
