{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook gathers the necissary data from 3 different data sources:\n",
    " - 2022Q3 Divvy bike/trip data found on [Divvy's Data Portal](https://divvy-tripdata.s3.amazonaws.com/index.html)\n",
    " - Estimated travel time using  [Open Source Routing Machine (OSRM) API](http://project-osrm.org/docs/v5.10.0/api/#general-options)\n",
    " - Historic weather data from [OpenWeather API](https://openweathermap.org/api/one-call-3#data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Setup Libraries and File Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import datetime\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from scrapy.selector import Selector\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create file location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = os.getcwd()\n",
    "SAVE_FILES = os.path.join(ROOT, \"DATA\")\n",
    "SAVE_FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Pull the September Divvy Bike Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(f\"https://divvy-tripdata.s3.amazonaws.com/202209-divvy-tripdata.zip\")\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall(SAVE_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sept_df = pd.read_csv('C:\\\\Users\\\\Nicholas\\\\Desktop\\\\Masters - Classes\\\\MSDS436\\\\Final\\\\MSDS436-FINAL\\\\DATA\\\\202209-divvy-publictripdata.csv')\n",
    "sept_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clean data\n",
    "- Order start_at in decending order\n",
    "- Drop all rows that do not have a start and end station\n",
    "- Pull between 1,000-2,000 data points per day\n",
    "- Pull weather data for 24h per day (720 rows total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order start_at in decending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sept_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sept_df['started_at'] = pd.to_datetime(sept_df['started_at'])\n",
    "sept_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sept_df = sept_df.sort_values(by='started_at')\n",
    "\n",
    "display(len(sept_df))\n",
    "sept_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all rows that do not have a start and end station name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sept_df = sept_df[sept_df['start_station_name'].notnull()]\n",
    "sept_df = sept_df[sept_df['end_station_name'].notnull()]\n",
    "\n",
    "display(len(sept_df))\n",
    "sept_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab up to 2,000 rows per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get just date column\n",
    "sept_df['started_at_clean'] = sept_df['started_at'].dt.date.astype(str)\n",
    "sept_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unique date list\n",
    "date_ls = sept_df['started_at_clean'].unique().tolist()\n",
    "date_ls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for date in date_ls:\n",
    "    if cnt == 0:\n",
    "        main_df = sept_df[sept_df['started_at_clean'] == date].sample(n=2000, random_state=0)\n",
    "        cnt =+ 1\n",
    "    else:\n",
    "        filter_df = sept_df[sept_df['started_at_clean'] == date].sample(n=2000, random_state=0)\n",
    "        main_df = pd.concat([main_df, filter_df], ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(len(main_df))\n",
    "\n",
    "main_df.index.name = 'row'\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check data\n",
    "# main_df.to_csv(\"data_check.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Get estimated travel time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new method per https://github.com/Project-OSRM/osrm-backend/issues/6258\n",
    "def get_distance_bike(point1: dict, point2: dict) -> tuple:\n",
    "    \"\"\"Gets distance between two points en route using http://project-osrm.org/docs/v5.10.0/api/#nearest-service\"\"\"\n",
    "    \n",
    "    url = f\"\"\"https://routing.openstreetmap.de/routed-bike/route/v1/biking/{point1[\"start_lng\"]},{point1[\"start_lat\"]};{point2[\"end_lng\"]},{point2[\"end_lat\"]}?overview=false&alternatives=false\"\"\"\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    # get the distance from the returned values\n",
    "    route = json.loads(r.content)[\"routes\"][0]\n",
    "    return (route[\"distance\"], route[\"duration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distances and durations\n",
    "dist_array_bike = []\n",
    "for i , r in tqdm(main_df.iterrows()):\n",
    "    try:\n",
    "        point1 = {\"start_lat\": r[\"start_lat\"], \"start_lng\": r[\"start_lng\"]}\n",
    "        point2 = {\"end_lat\": r[\"end_lat\"], \"end_lng\": r[\"end_lng\"]}\n",
    "        dist, duration = get_distance_bike(point1, point2)\n",
    "        #dist = geodesic((i_lat, i_lon), (o[\"CapitalLatitude\"], o[\"CapitalLongitude\"])).km\n",
    "        dist_array_bike.append((i, duration, dist))\n",
    "    except KeyError:\n",
    "        dist_array_bike.append((i, 0, 0))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_bike_df = pd.DataFrame(dist_array_bike,columns=[\"row\",\"duration (s)\",\"distance (m)\"])\n",
    "\n",
    "display(len(distances_bike_df))\n",
    "distances_bike_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matches key value for 'row' or any other unique identifier we want to assign later on\n",
    "sep_dis_df = pd.merge(main_df, distances_bike_df, on='row', how='right').drop('row', axis=1)\n",
    "sep_dis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data frame\n",
    "sep_dis_df.to_csv(\"202209_divvy_distance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Collect historic weather data\n",
    "- Chicago lat: 41.87\n",
    "- Chicago long: 87.62\n",
    "- Pull hourly data for all 30 days (720 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load save file\n",
    "sep_dis_df = pd.read_csv(\"202209_divvy_distance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time_ls = []\n",
    "unix_dt_ls = []\n",
    "\n",
    "for day in range(1, 30):\n",
    "    for hour in range(0, 24):\n",
    "        date_time = datetime.datetime(2022, 9, day, hour, 0)\n",
    "        unix_timestamp = datetime.datetime.timestamp(date_time)\n",
    "        \n",
    "        date_time_ls.append(date_time)\n",
    "        unix_dt_ls.append(unix_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696\n",
      "696\n"
     ]
    }
   ],
   "source": [
    "print(len(date_time_ls))\n",
    "print(len(unix_dt_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2022, 9, 1, 0, 0),\n",
       " datetime.datetime(2022, 9, 1, 1, 0),\n",
       " datetime.datetime(2022, 9, 1, 2, 0),\n",
       " datetime.datetime(2022, 9, 1, 3, 0),\n",
       " datetime.datetime(2022, 9, 1, 4, 0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_time_ls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1662008400, 1662012000, 1662015600, 1662019200, 1662022800]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove decimal in unix time\n",
    "unix_dt_ls = list(map(int, unix_dt_ls))\n",
    "unix_dt_ls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weathermap(latnum, lngnum, dtnum):\n",
    "    '''\n",
    "    Pulls weather data using lat, long, and unix_dt\n",
    "    '''\n",
    "    api_url = f\"http://api.openweathermap.org/data/3.0/onecall/timemachine?lat={latnum}&lon={lngnum}&dt={dtnum}&units=imperial&appid={config.api_key}\"\n",
    "    response = requests.get(api_url)\n",
    "    resp = response.json()\n",
    "    \n",
    "    temp = resp['data'][0]['temp']\n",
    "    hum = resp['data'][0]['humidity']\n",
    "    windsp = resp['data'][0]['wind_speed']\n",
    "    weather = resp['data'][0]['weather'][0]['main']\n",
    "    try:\n",
    "        rain = resp['data'][0]['rain']['1h']\n",
    "    except KeyError as ke:\n",
    "        rain = 0    \n",
    "    try:\n",
    "        snow = resp['data'][0]['snow']['1h']\n",
    "    except KeyError as ke:\n",
    "        snow = 0\n",
    "    \n",
    "    return temp, hum, windsp, weather, rain, snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/696 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-816f98fe45b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mlngnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m87.62\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mdtnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mtemp_ls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweathermap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlngnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mhum_ls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweathermap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlngnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mwindsp_ls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweathermap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlngnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-f672d7f5d47a>\u001b[0m in \u001b[0;36mweathermap\u001b[1;34m(latnum, lngnum, dtnum)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'temp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mhum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'humidity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mwindsp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'wind_speed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "temp_ls = []\n",
    "hum_ls = []\n",
    "windsp_ls = []\n",
    "weather_ls = []\n",
    "rain_ls = []\n",
    "snow_ls = []\n",
    "\n",
    "\n",
    "for unix in tqdm(unix_dt_ls):\n",
    "    try:\n",
    "        latnum = 41.87\n",
    "        lngnum = -87.62\n",
    "        dtnum = unix\n",
    "        temp_ls.append(weathermap(latnum, lngnum, dtnum)[0])\n",
    "        hum_ls.append(weathermap(latnum, lngnum, dtnum)[1])\n",
    "        windsp_ls.append(weathermap(latnum, lngnum, dtnum)[2])\n",
    "        weather_ls.append(weathermap(latnum, lngnum, dtnum)[3])\n",
    "        rain_ls.append(weathermap(latnum, lngnum, dtnum)[4])\n",
    "        snow_ls.append(weathermap(latnum, lngnum, dtnum)[5])\n",
    "    except NameError:\n",
    "        temp_ls.append('Nan')\n",
    "        hum_ls.append('Nan')\n",
    "        windsp_ls.append('Nan')\n",
    "        weather_ls.append('Nan')\n",
    "        rain_ls.append('Nan')\n",
    "        snow_ls.append('Nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "latnum = 41.87\n",
    "lngnum = -87.62\n",
    "\n",
    "api_url = f\"http://api.openweathermap.org/data/3.0/onecall/timemachine?lat={latnum}&lon={lngnum}&dt={unix_dt_ls[0]}&units=imperial&appid={config.api_key}\"\n",
    "response = requests.get(api_url)\n",
    "resp = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cod': 429,\n",
       " 'message': 'Your account is temporary blocked due to exceeding of requests limitation of your subscription type. Please choose the proper subscription https://openweathermap.org/price'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame(list(zip(unix_dt_ls, temp_ls, hum_ls, windsp_ls, \n",
    "                                weather_ls, rain_ls, snow_ls)),\n",
    "               columns =['unix_dt', 'temp', 'hum', 'windsp', \n",
    "                         'weather', 'rain', 'snow'])\n",
    "\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Script\n",
    "If we had more time, we would use the below code to pull a years worthof bike data and loop through the APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Pull Divvy Bike Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull keys from website using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = 'https://divvy-tripdata.s3.amazonaws.com'\n",
    "page = requests.get(main_url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_keys = soup.findAll('key')\n",
    "len(zip_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through Keys and only keep divvy-tripdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_ls = []\n",
    "\n",
    "for i in tqdm(range(len(zip_keys))):\n",
    "    key_ls.append(zip_keys[i].text)\n",
    "\n",
    "key_ls_clean = [ x for x in key_ls if \"divvy-tripdata\" in x ]\n",
    "\n",
    "key_ls_clean[27:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull and save all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for zip_f in key_ls_clean[27:30]:\n",
    "    r = requests.get(f\"https://divvy-tripdata.s3.amazonaws.com/{zip_f}\")\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    z.extractall(SAVE_FILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For our data purpose, read in the 2022Q3 files and create 1 master file\n",
    "- '202207-divvy-tripdata.csv',\n",
    "- '202208-divvy-tripdata.csv',\n",
    "- '202209-divvy-tripdata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 202207, 202208, and 202209 files and save file path in list\n",
    "file_ls = []\n",
    "\n",
    "for file in os.listdir(SAVE_FILES):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_ls.append(os.path.join(SAVE_FILES, file))\n",
    "    \n",
    "file_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through files, create pandas data frame, and save in dictonary\n",
    "df_dict = {}\n",
    "\n",
    "for i in file_ls:\n",
    "    for num in range(len(file_ls)):\n",
    "        df = pd.read_csv(i)\n",
    "        df_dict[f\"df_{num}\"] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab dictonary keys and check dataframe\n",
    "dict_keys_ls = list(df_dict.keys())\n",
    "df_dict[dict_keys_ls[2]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_df = df_dict[dict_keys_ls[2]]\n",
    "sep_df.index.name = 'row'\n",
    "len(sep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_df[:10000].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concat all 3 data frames and generate Q3_df\n",
    "# Q3_df = pd.concat([df_dict[dict_keys_ls[0]], df_dict[dict_keys_ls[1]], df_dict[dict_keys_ls[2]]], ignore_index=True, axis=0)\n",
    "# display(len(Q3_df))\n",
    "# display(Q3_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get random sample from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(n=883, random_state=0)\n",
    "display(len(df_sample))\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Get estimated travel time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new method per https://github.com/Project-OSRM/osrm-backend/issues/6258\n",
    "def get_distance_bike(point1: dict, point2: dict) -> tuple:\n",
    "    \"\"\"Gets distance between two points en route using http://project-osrm.org/docs/v5.10.0/api/#nearest-service\"\"\"\n",
    "    \n",
    "    url = f\"\"\"https://routing.openstreetmap.de/routed-bike/route/v1/biking/{point1[\"start_lng\"]},{point1[\"start_lat\"]};{point2[\"end_lng\"]},{point2[\"end_lat\"]}?overview=false&alternatives=false\"\"\"\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    # get the distance from the returned values\n",
    "    route = json.loads(r.content)[\"routes\"][0]\n",
    "    return (route[\"distance\"], route[\"duration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distances and durations\n",
    "dist_array_bike = []\n",
    "for i , r in tqdm(sep_df.iterrows()):\n",
    "    try:\n",
    "        point1 = {\"start_lat\": r[\"start_lat\"], \"start_lng\": r[\"start_lng\"]}\n",
    "        point2 = {\"end_lat\": r[\"end_lat\"], \"end_lng\": r[\"end_lng\"]}\n",
    "        dist, duration = get_distance_bike(point1, point2)\n",
    "        #dist = geodesic((i_lat, i_lon), (o[\"CapitalLatitude\"], o[\"CapitalLongitude\"])).km\n",
    "        dist_array_bike.append((i, duration, dist))\n",
    "    except KeyError:\n",
    "        dist_array_bike.append((i, 0, 0))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_array_bike[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure values are different\n",
    "# print(dist_array_car) ---> [(0, 800.9, 3224.7), (1, 1289.7, 4141.1)]\n",
    "print(len(dist_array_bike))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_bike_df = pd.DataFrame(dist_array_bike,columns=[\"row\",\"duration (s)\",\"distance (m)\"])\n",
    "distances_bike_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matches key value for 'row' or any other unique identifier we want to assign later on\n",
    "sep_dis_df = pd.merge(sep_df.iloc[:290673], distances_bike_df, on='row', how='right').drop('row', axis=1)\n",
    "sep_dis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data frame\n",
    "sep_dis_df.to_csv(\"202209_divvy_distance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# export master file\n",
    "# Q3_df.to_csv(\"2022Q3_divvy-tripdata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Collect historic weather data\n",
    "**NOTE:** the config.py file contains api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data for weatehr API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round lat and long to 2 decimal places (needed for API)\n",
    "sep_dis_df['start_lat_clean'] = sep_dis_df['start_lat'].round(2)\n",
    "sep_dis_df['start_lng_clean'] = sep_dis_df['start_lng'].round(2)\n",
    "\n",
    "sep_dis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_dis_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_dis_df['unix_dt'] = pd.to_datetime(sep_dis_df['started_at'])\n",
    "sep_dis_df['unix_dt'] = pd.to_datetime(sep_dis_df['unix_dt'])\n",
    "sep_dis_df['unix_dt'] = pd.to_numeric(sep_dis_df['unix_dt'])\n",
    "sep_dis_df['unix_dt'] = sep_dis_df['unix_dt'] // 10 ** 9\n",
    "\n",
    "sep_dis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weathermap(latnum, lngnum, dtnum):\n",
    "    '''\n",
    "    Pulls weather data using lat, long, and unix_dt\n",
    "    '''\n",
    "    api_url = f\"http://api.openweathermap.org/data/3.0/onecall/timemachine?lat={latnum}&lon={lngnum}&dt={dtnum}&units=imperial&appid={config.api_key}\"\n",
    "    response = requests.get(api_url)\n",
    "    resp = response.json()\n",
    "    \n",
    "    temp = resp['data'][0]['temp']\n",
    "    hum = resp['data'][0]['humidity']\n",
    "    windsp = resp['data'][0]['wind_speed']\n",
    "    weather = resp['data'][0]['weather'][0]['main']\n",
    "    try:\n",
    "        rain = resp['data'][0]['rain']['1h']\n",
    "    except KeyError as ke:\n",
    "        rain = 0    \n",
    "    try:\n",
    "        snow = resp['data'][0]['snow']['1h']\n",
    "    except KeyError as ke:\n",
    "        snow = 0\n",
    "    \n",
    "    return temp, hum, windsp, weather, rain, snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ls = []\n",
    "hum_ls = []\n",
    "windsp_ls = []\n",
    "weather_ls = []\n",
    "rain_ls = []\n",
    "snow_ls = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(sep_dis_df))):\n",
    "    try:\n",
    "        latnum = sep_dis_df['start_lat'].iloc[i]\n",
    "        lngnum = sep_dis_df['start_lng'].iloc[i]\n",
    "        dtnum = sep_dis_df['unix_dt'].iloc[i]\n",
    "        temp_ls.append(weathermap(latnum, lngnum, dtnum)[0])\n",
    "        hum_ls.append(weathermap(latnum, lngnum, dtnum)[1])\n",
    "        windsp_ls.append(weathermap(latnum, lngnum, dtnum)[2])\n",
    "        weather_ls.append(weathermap(latnum, lngnum, dtnum)[3])\n",
    "        rain_ls.append(weathermap(latnum, lngnum, dtnum)[4])\n",
    "        snow_ls.append(weathermap(latnum, lngnum, dtnum)[5])\n",
    "    except NameError:\n",
    "        temp_ls.append('Nan')\n",
    "        hum_ls.append('Nan')\n",
    "        windsp_ls.append('Nan')\n",
    "        weather_ls.append('Nan')\n",
    "        rain_ls.append('Nan')\n",
    "        snow_ls.append('Nan')\n",
    "    \n",
    "sep_dis_df['temp'] = temp_ls\n",
    "sep_dis_df['hum'] = hum_ls\n",
    "sep_dis_df['windsp'] = windsp_ls\n",
    "sep_dis_df['weather'] = weather_ls\n",
    "sep_dis_df['rain'] = rain_ls\n",
    "sep_dis_df['snow'] = snow_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join historic weather data to sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temp'] = temp_ls\n",
    "df['hum'] = hum_ls\n",
    "df['windsp'] = windsp_ls\n",
    "df['weather'] = weather_ls\n",
    "df['rain'] = rain_ls\n",
    "df['snow'] = snow_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data in AWS S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latnum = sep_dis_df['start_lat'].iloc[0]\n",
    "latnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lngnum = sep_dis_df['start_lng'].iloc[0]\n",
    "lngnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtnum = sep_dis_df['unix_dt'].iloc[i]\n",
    "dtnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = f\"http://api.openweathermap.org/data/3.0/onecall/timemachine?lat={latnum}&lon={lngnum}&dt={dtnum}&units=imperial&appid={config.api_key}\"\n",
    "response = requests.get(api_url)\n",
    "resp = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
